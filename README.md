# BigDataLabs

Un projet complet couvrant les technologies Big Data : **Hadoop MapReduce**, **Kafka**, **HBase**, **Pig**, et **Hive**.

---

## ğŸ“‹ Structure du Projet

```
BigDataLabs/
â”œâ”€â”€ datasets/                          # DonnÃ©es brutes et scripts de traitement
â”‚   â”œâ”€â”€ alice.txt, calls.txt, coran_converted.txt
â”‚   â”œâ”€â”€ Mapper.py, Reducer.py          # Scripts Python MapReduce
â”‚   â”œâ”€â”€ purchases.txt
â”‚   â””â”€â”€ DATSETS_HIVE/
â”‚       â”œâ”€â”€ clients.txt, hotels.txt, reservations.txt
â”‚       â””â”€â”€ hadoop-project/
â”œâ”€â”€ lab0/                              # Configuration initiale (Docker)
â”‚   â”œâ”€â”€ docker-compose.yaml
â”‚   â””â”€â”€ datasets/
â”œâ”€â”€ lab1/                              # Hadoop MapReduce (Java & Python)
â”‚   â”œâ”€â”€ hadoop_lab/                    # Projet Maven WordCount
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ src/main/java/...
â”‚   â””â”€â”€ results/                       # RÃ©sultats MapReduce
â”œâ”€â”€ lab3_kafka/                        # Apache Kafka (Producteur/Consommateur)
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/.../
â”œâ”€â”€ lab4_hbase/                        # HBase (stockage NoSQL)
â”œâ”€â”€ lab5_pig/                          # Pig Latin (ETL & analyse)
â”œâ”€â”€ lab6_hive/                         # Hive (SQL sur donnÃ©es structurÃ©es)
â”‚   â”œâ”€â”€ Creation.hql                   # CrÃ©ation tables
â”‚   â”œâ”€â”€ Loading.hql                    # Chargement donnÃ©es
â”‚   â”œâ”€â”€ Queries.hql                    # RequÃªtes analytiques
â”‚   â””â”€â”€ results.txt
â””â”€â”€ README.md                          # Ce fichier
```

---

## ğŸ¯ Objectifs par Lab

### Lab 0 : Configuration Docker
- **Objectif** : Mettre en place l'environnement Hadoop/Hive en conteneurs.
- **Fichier clÃ©** : `docker-compose.yaml`
- **Commandes** :
  ```bash
  docker-compose up -d
  docker-compose ps
  docker-compose down
  ```

### Lab 1 : Hadoop MapReduce
- **Objectif** : ImplÃ©menter MapReduce en Java et Python.
- **Cas d'usage** : Comptage de mots (WordCount), calculs sur donnÃ©es.
- **Fichiers clÃ©s** :
  - `hadoop_lab/src/main/java/.../WordCount.java`
  - `hadoop_lab/src/main/java/.../TokenizerMapper.java`
  - `hadoop_lab/src/main/java/.../IntSumReducer.java`
- **Build & ExÃ©cution** :
  ```bash
  cd lab1/hadoop_lab
  mvn clean package
  hadoop jar target/WordCount.jar org.apache.hadoop.examples.WordCount <input> <output>
  ```

### Lab 3 : Apache Kafka
- **Objectif** : Architecture pub/sub avec producteur et consommateur.
- **Fichiers clÃ©s** :
  - `EventProducer.java` : Envoie messages
  - `EventConsumer.java` : Consomme messages
- **Build** :
  ```bash
  cd lab3_kafka
  mvn clean package
  java -cp target/classes:target/dependency/* edu.ensias.kafka.EventProducer
  java -cp target/classes:target/dependency/* edu.ensias.kafka.EventConsumer
  ```

### Lab 4 : HBase
- **Objectif** : Stockage colonnaire distribuÃ©, requÃªtes NoSQL.
- **Dossier** : `lab4_hbase/`

### Lab 5 : Pig Latin
- **Objectif** : Langage de haut niveau pour ETL et transformation.
- **Scripts** : Ã€ placer dans `lab5_pig/`
- **Exemple de script** :
  ```pig
  clients = LOAD 'clients.txt' AS (id:int, name:chararray, email:chararray);
  filtered = FILTER clients BY id > 2;
  DUMP filtered;
  ```

### Lab 6 : Apache Hive
- **Objectif** : SQL sur donnÃ©es structurÃ©es (HDFS/Hadoop).
- **DonnÃ©es** : RÃ©servations hÃ´tels (clients, hÃ´tels, rÃ©servations).
- **Fichiers clÃ©s** :
  - `Creation.hql` : CrÃ©e tables (avec OpenCSVSerde, partitionnement)
  - `Loading.hql` : Charge donnÃ©es + transformation via INSERT OVERWRITE
  - `Queries.hql` : RequÃªtes analytiques (JOIN, GROUP BY, agrÃ©gations)

---

## ğŸ“Š DonnÃ©es Lab 6 (Hive)

### Fichier `clients.txt`
```
1,John Doe,john.doe@example.com,1234567890
2,Sarah Connor,sarah.connor@example.com,0987654321
3,James Bond,james.bond@example.com,1122334455
...
```

### Fichier `hotels.txt`
```
1,Grand Hotel,Paris,5
2,Beach Resort,Nice,4
3,Mountain Lodge,Chamonix,3
...
```

### Fichier `reservations.txt`
```
1,1,1,2024-12-01,2024-12-05,1500.00
2,2,2,2024-12-10,2024-12-15,800.00
...
```

---

## ğŸš€ ExÃ©cution Lab 6 (Hive)

### 1ï¸âƒ£ CrÃ©er les tables
```bash
hive -f lab6_hive/Creation.hql
```

### 2ï¸âƒ£ Charger les donnÃ©es
```bash
hive -f lab6_hive/Loading.hql
```

### 3ï¸âƒ£ ExÃ©cuter les requÃªtes
```bash
hive -f lab6_hive/Queries.hql
```

Ou en mode interactif (Beeline) :
```bash
beeline -u jdbc:hive2://localhost:10000 -f lab6_hive/Creation.hql
```

---

## ğŸ”§ Points ClÃ©s d'ImplÃ©mentation

### OpenCSVSerde (Hive)
Pour Ã©viter les erreurs de parsing CSV :
```sql
CREATE TABLE raw_clients (
  id STRING, name STRING, email STRING, phone STRING
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES ("separatorChar" = ",")
STORED AS TEXTFILE;
```

### Tables de Staging (raw_*)
- Chargent les fichiers bruts en STRING.
- Ã‰vitent les erreurs de type lors du LOAD DATA.
- INSERT OVERWRITE avec CAST vers tables finales typÃ©es.

### Partitionnement
```sql
PARTITIONED BY (date_debut STRING)
```
Les dates sont en STRING pour Ã©viter les erreurs lors du chargement.

### Bucketing
```sql
CLUSTERED BY (client_id) INTO 4 BUCKETS
STORED AS ORC;
```
AmÃ©liore les JOIN et GROUP BY sur `client_id`.

---

## ğŸ“ RequÃªtes Utiles (Lab 6)

### Revenus par hÃ´tel
```sql
SELECT h.nom, SUM(r.prix_total) AS total_revenus
FROM reservations r
JOIN hotels_partitioned h ON r.hotel_id = h.hotel_id
GROUP BY h.nom
ORDER BY total_revenus DESC;
```

### Nombre de rÃ©servations par client
```sql
SELECT c.nom, COUNT(*) AS nb_reservations
FROM reservations r
JOIN clients c ON r.client_id = c.client_id
GROUP BY c.nom;
```

### HÃ´tels sans rÃ©servation
```sql
SELECT h.nom
FROM hotels_partitioned h
LEFT JOIN reservations r ON h.hotel_id = r.hotel_id
WHERE r.reservation_id IS NULL;
```

---

## ğŸ› ï¸ DÃ©pendances

- **Java** : OpenJDK 8+
- **Hadoop** : 3.x
- **Hive** : 3.x
- **Kafka** : 2.x
- **HBase** : 2.x
- **Pig** : 0.17+
- **Maven** : 3.6+
- **Docker** : 20.10+ (pour Lab 0)

---

## ğŸ“¦ Installation

1. **Cloner le projet** :
   ```bash
   git clone https://github.com/Abderrahmane-dotcom/BigDataLabs.git
   cd BigDataLabs
   ```

2. **VÃ©rifier Maven** :
   ```bash
   mvn --version
   ```

3. **Builder les projets Java** :
   ```bash
   cd lab1/hadoop_lab && mvn clean package
   cd ../../lab3_kafka && mvn clean package
   ```

4. **Lancer Docker (Lab 0)** :
   ```bash
   cd lab0
   docker-compose up -d
   ```

---

## ğŸ“š Ressources

- [Apache Hadoop Documentation](https://hadoop.apache.org/docs/)
- [Apache Hive Documentation](https://hive.apache.org/)
- [Apache Pig Documentation](https://pig.apache.org/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache HBase Documentation](https://hbase.apache.org/)

---

## ğŸ¤ Auteur

**Abderrahmane** - [GitHub](https://github.com/Abderrahmane-dotcom)

---

## ğŸ“„ Licence

Projet Ã©ducatif - BigDataLabs (2024-2025)
